{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import os\n",
    "import sys\n",
    "from scipy import signal\n",
    "\n",
    "resampling = 'resampled'\n",
    "depth_list = ['GM']\n",
    "nruns = 4\n",
    "subject = 'sub-46'\n",
    "session = '02'\n",
    "task = 'RET'\n",
    "\n",
    "\n",
    "# For me it is only one depth = GM \n",
    "for depth in range(len(depth_list)):\n",
    "    proc_tc_RH = [] # Store the time course form the Right Hemisphere\n",
    "    proc_tc_LH = [] # Store the time course form the Left Hemisphere\n",
    "\n",
    "    for run in range(nruns): # Approximately 4 runs \n",
    "        # Load GIFTI files for left and right hemispheres\n",
    "        proc_tc_L = nib.load(\n",
    "            f'{MAIN_PATH}/{resampling}/{subject}/ses-{session}/{denoising}/{subject}_ses-{session}_task-{task}_run-{run + 1}_space-fsnative_hemi-L_desc-{denoising}_bold_GM.gii')\n",
    "        proc_tc_R = nib.load(\n",
    "            f'{MAIN_PATH}/{resampling}/{subject}/ses-{session}/{denoising}/{subject}_ses-{session}_task-{task}_run-{run + 1}_space-fsnative_hemi-R_desc-{denoising}_bold_GM.gii')\n",
    "\n",
    "        # Aggregate the data for the hemisphere separately \n",
    "        tc_R = proc_tc_R.agg_data().T  # (time points, vertices)\n",
    "        tc_L = proc_tc_L.agg_data().T  # (time points, vertices)\n",
    "        print(tc_R.shape)\n",
    "        # Not needed now \n",
    "        #if tc_R.shape[0] > 136:\n",
    "        #    tc_R = tc_R[:136, :]\n",
    "        #    print(tc_R.shape)\n",
    "        #if tc_L.shape[0] > 136:\n",
    "        #    tc_L = tc_L[:136, :]\n",
    "\n",
    "        # Normalize \n",
    "        tc_m_R = tc_R * np.expand_dims(np.nan_to_num((100 / np.mean(tc_R, axis=0))), axis=0)\n",
    "        tc_m_L = tc_L * np.expand_dims(np.nan_to_num((100 / np.mean(tc_L, axis=0))), axis=0)\n",
    "\n",
    "        # Baseline correction\n",
    "        baseline_R = np.median(tc_m_R[:5], axis=0)\n",
    "        baseline_L = np.median(tc_m_L[:5], axis=0)\n",
    "\n",
    "        tc_m_R = tc_m_R - baseline_R\n",
    "        tc_m_L = tc_m_L - baseline_L\n",
    "\n",
    "        # Filter if enabled\n",
    "        if filter == 1:\n",
    "            mean_R = np.mean(tc_m_R, axis=0)\n",
    "            mean_L = np.mean(tc_m_L, axis=0)\n",
    "\n",
    "            tc_m_R = signal.detrend(tc_m_R, axis=0) + mean_R\n",
    "            tc_m_L = signal.detrend(tc_m_L, axis=0) + mean_L\n",
    "\n",
    "            # Highpass-filtering\n",
    "            TR = 1.5\n",
    "            fs = 1 / TR\n",
    "            lowcut = 0.006\n",
    "            nyquist = 0.5 * fs\n",
    "            f_low = lowcut / nyquist\n",
    "            sos = signal.butter(8, [f_low], 'highpass', fs=fs, output='sos')\n",
    "            tc_m_R = signal.sosfiltfilt(sos, tc_m_R, axis=0)\n",
    "            tc_m_L = signal.sosfiltfilt(sos, tc_m_L, axis=0)\n",
    "\n",
    "        # Store processed data for saving\n",
    "        proc_tc_RH.append(tc_m_R)\n",
    "        proc_tc_LH.append(tc_m_L)\n",
    "\n",
    "    # Compute median time course across runs\n",
    "    mean_proc_tc_RH = np.median(np.array(proc_tc_RH), axis=0)\n",
    "    mean_proc_tc_LH = np.median(np.array(proc_tc_LH), axis=0)\n",
    "\n",
    "    # Save the processed time courses for RH and LH separately\n",
    "    path = f'{MAIN_PATH}/pRFM/{subject}/ses-{session}/{denoising}/'\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    np.save(f'{path}{subject}_ses-{session}_task-{task}_hemi-rh_desc-avg_bold_GM.npy', mean_proc_tc_RH)\n",
    "    np.save(f'{path}{subject}_ses-{session}_task-{task}_hemi-lh_desc-avg_bold_GM.npy', mean_proc_tc_LH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0k/zjsxn2197mdbzvx14lj8m0v00000gn/T/ipykernel_63170/1011283980.py:23: RuntimeWarning: divide by zero encountered in divide\n",
      "  tc_m = tc * np.expand_dims(np.nan_to_num((100 / np.mean(tc, axis=0))), axis=0)\n"
     ]
    }
   ],
   "source": [
    "MAIN_PATH = '/Volumes/FedericaCardillo/pre-processing/projects/PROJECT_EGRET-AAA/derivatives'\n",
    "subject = 'sub-46'\n",
    "session = '02'\n",
    "denoising = 'nordic'\n",
    "depth_list = 'GM'\n",
    "nruns = 4\n",
    "resampling = 'resampled'\n",
    "task = 'RET'\n",
    "\n",
    "for depth in range(depth_list.__len__()):\n",
    "    proc_tc_L = []\n",
    "    proc_tc_R = []\n",
    "    proc_tc = []\n",
    "    for run in range(nruns):\n",
    "        proc_tc_L = nib.load(\n",
    "            f'{MAIN_PATH}/{resampling}/{subject}/ses-{session}/{denoising}/{subject}_ses-{session}_task-{task}_run-{run + 1}_space-fsnative_hemi-L_desc-{denoising}_bold_GM.gii')\n",
    "        proc_tc_R = nib.load(\n",
    "            f'{MAIN_PATH}/{resampling}/{subject}/ses-{session}/{denoising}/{subject}_ses-{session}_task-{task}_run-{run + 1}_space-fsnative_hemi-R_desc-{denoising}_bold_GM.gii')\n",
    "        tc = np.vstack([proc_tc_L.agg_data(), proc_tc_R.agg_data()]).T\n",
    "        if tc.shape[0]>136:\n",
    "            tc=tc[:,:] \n",
    "        tc=tc[:,:] \n",
    "        tc_m = tc * np.expand_dims(np.nan_to_num((100 / np.mean(tc, axis=0))), axis=0) \n",
    "\n",
    "        # Baseline correction\n",
    "        baseline = np.median(tc_m[:5], axis=0)\n",
    "        tc_m = tc_m - baseline # ORIGINAL TIME COURSE\n",
    "\n",
    "        if filter==1:\n",
    "            from scipy import signal\n",
    "            mean=np.mean(tc_m, axis=0) # Remove linear trend without demeaning\n",
    "            tc_m=signal.detrend(tc_m, axis=0)+mean\n",
    "            # Highpass-filtering\n",
    "            TR = 1.5                                                            ## TR is the time between successive MRI scans, measured in seconds.                              \n",
    "            fs = 1 / TR  # Hz                                                   ## FS is the sampling frequency, which is the number of samples per second. It's the inverse of the TR.\n",
    "            lowcut=0.006 # cut-off freq of the filter                            ## Lowcut and highcut define the frequency range for the high-pass filter. Only the lowcut frequency is used.\n",
    "            highcut=0.015 # cut-off freq of the filter\n",
    "            nyquist=0.5*fs                                                      ## Nyquist frequency is half the sampling frequency.\n",
    "            f_low = lowcut/nyquist;                                             ## The cut-off frequencies are normalized. (e.i 0,02 )\n",
    "            f_high = highcut/nyquist;\n",
    "            sos = signal.butter(8, [f_low],'highpass', fs=fs,output='sos')      ## Azzurra used low-pass 4th order Butterworth filter with a cut-off frequency of 0.1 Hz\n",
    "            tc_m = signal.sosfiltfilt(sos, tc_m, axis=0)\n",
    "\n",
    "        proc_tc.append(tc_m)\n",
    "    mean_proc_tc = np.median(np.array(proc_tc), axis=0)\n",
    "    psc = (mean_proc_tc) # FILTERED TIME COURSE\n",
    "\n",
    "    path=f'{MAIN_PATH}/pRFM/{subject}/ses-{session}/{denoising}/'\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    np.save(f'{MAIN_PATH}/pRFM/{subject}/ses-{session}/{denoising}/{subject}_ses-{session}_task-{task}_hemi-LR_desc-avg_bold_{depth_list[depth]}_trial.npy',psc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pRFfitting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
