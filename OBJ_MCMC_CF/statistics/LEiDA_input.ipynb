{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f650be6f",
   "metadata": {},
   "source": [
    "## Leading Eigenvector Dynamics Analysis (LEiDA) framework to fMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "984929f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b230cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = '/Volumes/FedericaCardillo/pre-processing/projects/PROJECT_EGRET-AAA' # Project directory \n",
    "bold_dir = os.path.join(MAIN_PATH, 'derivatives', 'pRFM') # BOLD file directory \n",
    "freesurfer_dir = os.path.join(MAIN_PATH, 'derivatives', 'freesurfer') # Freesurfer labels directory \n",
    "timeseries_output = os.path.join(MAIN_PATH, 'data', 'time_series')  # Output time series\n",
    "roi_output = os.path.join(MAIN_PATH, 'data', 'rois_coordinates.csv') # Output roi coordinates \n",
    "\n",
    "subjects = [f\"sub-{i:02}\" for i in range(2, 47)]\n",
    "sessions = ['ses-01', 'ses-02']\n",
    "rois = ['V1', 'V2', 'V3', 'V4', 'LO']\n",
    "hemis = ['lh', 'rh']\n",
    "roi_files = []\n",
    "for hemi in hemis:\n",
    "    for roi in rois:\n",
    "        label_filename = f\"{hemi}.manual_{roi}.label\"\n",
    "        label_name = f\"{hemi}.{roi}\"\n",
    "        roi_files.append((label_filename, label_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2329acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load and read the Freesurfer label to compute the center vertex as the average of x, y, z coordinates.\"\"\"\n",
    "def label_center(filepath):\n",
    "    coordinates = [] # Empty list to store the coordinates\n",
    "\n",
    "    with open(filepath, 'r') as f: # Open label in reading mode \n",
    "        lines = f.readlines() # Read all lines from the file into a list\n",
    "\n",
    "    for line in lines[2:]: # Itearte over all the lines ignoring the first two\n",
    "        parts = line.split() # Split the line into parts\n",
    "        # Get x, y, z coordinates (second, third, fourth values)\n",
    "        x = float(parts[1])\n",
    "        y = float(parts[2])\n",
    "        z = float(parts[3])\n",
    "        coordinates.append([x, y, z]) # Add the coordinates to the list\n",
    "\n",
    "    coordinates = np.array(coordinates)\n",
    "    center = coordinates.mean(axis=0) # # Calculate the mean x, y, z position\n",
    "    return center\n",
    "\n",
    "\"\"\"Get the FreeSurfer label to extract a list vertex indices.\"\"\"\n",
    "def load_label_indices(label_path):\n",
    "    indices = [] # Empty list to store vertex indices\n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Skip the first two lines (header)\n",
    "    for line in lines[2:]:\n",
    "        parts = line.split()\n",
    "        index = int(parts[0]) # Get the index from the first value in each line\n",
    "        indices.append(index) # Add the vertex index to the list\n",
    "\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7190331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No BOLD file for sub-03\n",
      "No BOLD file for sub-13\n",
      "No BOLD file for sub-14\n",
      "No BOLD file for sub-15\n",
      "No BOLD file for sub-16\n",
      "No BOLD file for sub-17\n",
      "No BOLD file for sub-18\n",
      "No BOLD file for sub-20\n",
      "No BOLD file for sub-24\n",
      "No BOLD file for sub-26\n",
      "No BOLD file for sub-37\n",
      "No BOLD file for sub-38\n",
      "No BOLD file for sub-39\n",
      "No BOLD file for sub-40\n",
      "No BOLD file for sub-41\n",
      "No BOLD file for sub-42\n",
      "No BOLD file for sub-43\n",
      "No BOLD file for sub-44\n",
      "No BOLD file for sub-45\n",
      "No BOLD file for sub-46\n"
     ]
    }
   ],
   "source": [
    "# EXtract the roi coordinates for a representative subject \n",
    "results = []  # Empty list to store the results: (label, x, y, z)\n",
    "for filename, label in roi_files:\n",
    "    label_path = os.path.join(freesurfer_dir, 'sub-46', 'label', filename) # Path to representative subject\n",
    "    center = label_center(label_path) # Compute the center as the average x, y, z\n",
    "    results.append((label, *center)) # Add the label name and its center\n",
    "\n",
    "# Save all center to a CSV file\n",
    "with open(roi_output, 'w', newline='') as f:\n",
    "    csv.writer(f).writerows(results)\n",
    "\n",
    "# Extract the time series for each subject\n",
    "for subject in subjects:\n",
    "    session_path = None  # Track which session is used\n",
    "    bold_path = None     # Full path to the BOLD time series file\n",
    "    for ses in sessions: # Try to find the BOLD file in either ses-01 or ses-02\n",
    "        temp_path = os.path.join(bold_dir, subject, ses, 'nordic', f'{subject}_{ses}_task-RestingState_hemi-LR_desc-avg_bold_GM.npy')\n",
    "        if os.path.exists(temp_path):\n",
    "            session_path = ses\n",
    "            bold_path = temp_path\n",
    "            break \n",
    "    if bold_path is None: # Skip the subject if no BOLD file was found\n",
    "        print(f'No BOLD file for {subject}')\n",
    "        continue\n",
    "    bold_data = np.load(bold_path).T # Load the BOLD data with vertices x timepoints\n",
    "    label_dir = os.path.join(freesurfer_dir, subject, 'label') # Label directory \n",
    "\n",
    "    # Collect all vertex indices from ROI label files\n",
    "    #all_indices = []\n",
    "    #for roi in rois: \n",
    "    #    for hemi in ['lh', 'rh']:\n",
    "    #        label_path = os.path.join(label_dir, f'{hemi}.manual_{roi}.label')\n",
    "    #        indices = load_label_indices(label_path)\n",
    "    #        all_indices.append(indices)\n",
    "\n",
    "    #all_indices = np.concatenate(all_indices) # Combine vertex indices\n",
    "    #selected_data = bold_data[all_indices, :] # Get the time series\n",
    "\n",
    "    # Save the ouput \n",
    "    #output_dir = os.path.join(timeseries_output, subject) # Subject specific directory \n",
    "    #os.makedirs(output_dir, exist_ok=True)\n",
    "    #output_path = os.path.join(output_dir, f'{subject}.csv')\n",
    "    #with open(output_path, 'w', newline='') as f:\n",
    "    #    csv.writer(f).writerows(selected_data)\n",
    "\n",
    "    # Compute average time series for each ROI and store in a list\n",
    "    averaged_timeseries = []\n",
    "\n",
    "    for roi in rois: \n",
    "        for hemi in ['lh', 'rh']:\n",
    "            label_name = f'{hemi}.{roi}'\n",
    "            label_path = os.path.join(label_dir, f'{hemi}.manual_{roi}.label')\n",
    "            indices = load_label_indices(label_path)\n",
    "\n",
    "            if not indices:\n",
    "                print(f\"No indices found for {label_name} in {subject}.\")\n",
    "                continue\n",
    "\n",
    "            roi_timeseries = bold_data[indices, :]           # shape: [num_vertices_in_roi x timepoints]\n",
    "            mean_timeseries = \n",
    "            [timepoints]\n",
    "            averaged_timeseries.append(mean_timeseries)\n",
    "\n",
    "    # Convert to array: [N_ROIs x N_timepoints]\n",
    "    averaged_timeseries = np.array(averaged_timeseries)\n",
    "\n",
    "    # Save the output\n",
    "    output_dir = os.path.join(timeseries_output, subject)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f'{subject}.csv')\n",
    "    np.savetxt(output_path, averaged_timeseries, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae73088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Collect all vertex indices from ROI label files\n",
    "    all_indices = []\n",
    "    for roi in rois: \n",
    "        for hemi in ['lh', 'rh']:\n",
    "            label_path = os.path.join(label_dir, f'{hemi}.manual_{roi}.label')\n",
    "            indices = load_label_indices(label_path)\n",
    "            all_indices.append(indices)\n",
    "\n",
    "    all_indices = np.concatenate(all_indices) # Combine vertex indices\n",
    "    selected_data = bold_data[all_indices, :] # Get the time series\n",
    "\n",
    "    # Save the ouput \n",
    "    output_dir = os.path.join(timeseries_output, subject) # Subject specific directory \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f'{subject}.csv')\n",
    "    with open(output_path, 'w', newline='') as f:\n",
    "        csv.writer(f).writerows(selected_data)\n",
    "\n",
    "\n",
    "⸻\n",
    "\n",
    "➕ Replace With This:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pRFfitting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
