{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Population Receptive Field properties for the Connective Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import pickle \n",
    "from nibabel.freesurfer.io import read_morph_data, write_morph_data\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = '/Volumes/FedericaCardillo/pre-processing/projects/PROJECT_EGRET-AAA/derivatives'\n",
    "freesurfer = f\"{MAIN_PATH}/freesurfer\"\n",
    "source = 'V1'\n",
    "atlas = 'manual'\n",
    "delineation = 'benson'\n",
    "denoising = 'nordic'\n",
    "\n",
    "subjects = [f'sub-{i:02}' for i in range(46, 46)]\n",
    "# tasks = ['RET2','RET', 'RestingState']\n",
    "tasks = ['RET2','RET']\n",
    "hemispheres = ['lh', 'rh']\n",
    "visual_areas = ['V1', 'V2', 'V3', 'LO', 'V4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Benson vertices: 125206\n",
      "Filtered vertices (0.5 <= ecc <= 10): 7383\n",
      "Example: [(0, 4.24), (1, 4.16), (2, 4.23), (3, 4.26), (4, 4.21)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from nibabel.freesurfer import read_morph_data\n",
    "\n",
    "class PRFModel:\n",
    "    def __init__(self, r2, size, ecc, angle):\n",
    "        self.r2 = r2\n",
    "        self.size = size\n",
    "        self.ecc = ecc\n",
    "        self.angle = angle\n",
    "\n",
    "def load_prf(subj, main_path, atlas, denoising, task):\n",
    "    if task == 'RestingState':\n",
    "        task_for_file = 'RET'\n",
    "    else:\n",
    "        task_for_file = task\n",
    "\n",
    "    for ses in ['ses-01', 'ses-02']:\n",
    "        filepath = os.path.join(\n",
    "            main_path,\n",
    "            f'pRFM/{subj}/{ses}/{denoising}/model-{atlas}-nelder-mead-GM_desc-prf_params_{task_for_file}.pkl'\n",
    "        )\n",
    "        if os.path.exists(filepath):\n",
    "            with open(filepath, 'rb') as file:\n",
    "                pkl_data = pickle.load(file)\n",
    "            prf_params = pkl_data['model'].iterative_search_params\n",
    "            prf_voxels = np.where(pkl_data['rois_mask'] == 1)[0]\n",
    "            return prf_params, prf_voxels\n",
    "\n",
    "    raise FileNotFoundError(f\"pRF .pkl file not found for subject {subj}.\")\n",
    "\n",
    "def filter_prf(prf_params):\n",
    "    return PRFModel(\n",
    "        r2=prf_params[:, 7],\n",
    "        size=prf_params[:, 2],\n",
    "        ecc=np.sqrt(prf_params[:, 1]**2 + prf_params[:, 0]**2),\n",
    "        angle=np.arctan2(prf_params[:, 1], prf_params[:, 0])\n",
    "    )\n",
    "\n",
    "def get_benson_vertices(label_file):\n",
    "    df = pd.read_csv(label_file, sep='\\s+', skiprows=2, header=None)\n",
    "    df.columns = ['vertex', 'x', 'y', 'z', 'value']\n",
    "    return df['vertex'].values\n",
    "\n",
    "def source_eccentricity_benson(subj, hemi, main_path, atlas, denoising, task, freesurfer_path, label_file):\n",
    "    prf_params, prf_voxels = load_prf(subj, main_path, atlas, denoising, task)\n",
    "    prf_model = filter_prf(prf_params)\n",
    "\n",
    "    lh_c = read_morph_data(os.path.join(freesurfer_path, subj, 'surf', 'lh.curv'))\n",
    "    numel_lh = lh_c.shape[0]\n",
    "\n",
    "    if hemi == 'rh':\n",
    "        adjusted_voxels = prf_voxels[prf_voxels >= numel_lh] - numel_lh\n",
    "        ecc = prf_model.ecc[prf_voxels >= numel_lh]\n",
    "    else:\n",
    "        adjusted_voxels = prf_voxels[prf_voxels < numel_lh]\n",
    "        ecc = prf_model.ecc[prf_voxels < numel_lh]\n",
    "\n",
    "    ecc_dict = dict(zip(adjusted_voxels, ecc))\n",
    "\n",
    "    # Load Benson vertices\n",
    "    benson_vertices = get_benson_vertices(label_file)\n",
    "\n",
    "    # Filter vertices by eccentricity range\n",
    "    filtered_vertices = [v for v in benson_vertices if v in ecc_dict and 0.5 <= ecc_dict[v] <= 10]\n",
    "\n",
    "    print(f\"Total Benson vertices: {len(benson_vertices)}\")\n",
    "    print(f\"Filtered vertices (0.5 <= ecc <= 10): {len(filtered_vertices)}\")\n",
    "    print(f\"Example: {[(v, round(ecc_dict[v], 2)) for v in filtered_vertices[:5]]}\")\n",
    "\n",
    "    return filtered_vertices\n",
    "\n",
    "# ==== USAGE ====\n",
    "subj = 'sub-46'\n",
    "hemi = 'lh'\n",
    "main_path = '/Volumes/FedericaCardillo/pre-processing/projects/PROJECT_EGRET-AAA/derivatives'\n",
    "atlas = 'manual'\n",
    "denoising = 'nordic'\n",
    "task = 'RET'\n",
    "freesurfer_path = f\"{main_path}/freesurfer\"\n",
    "label_file = f\"{freesurfer_path}/{subj}/label/{hemi}.benson14_varea-0001.label\"\n",
    "\n",
    "filtered_vertices = source_eccentricity_benson(subj, hemi, main_path, atlas, denoising, task, freesurfer_path, label_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRFModel:\n",
    "    def __init__(self, r2, size, ecc, angle):\n",
    "        self.r2 = r2        \n",
    "        self.size = size\n",
    "        self.ecc = ecc    \n",
    "        self.angle = angle     \n",
    "\n",
    "def pickle_file(filepath):\n",
    "    if not os.path.isfile(filepath):\n",
    "        raise FileNotFoundError(f\"File not found: {filepath}\")\n",
    "    with open(filepath, 'rb') as file: \n",
    "        return pickle.load(file)\n",
    "\n",
    "def load_prf(subj, main_path, atlas, denoising, task):\n",
    "    filename_task = 'RET' if task == 'RestingState' else task\n",
    "    filepath = os.path.join(\n",
    "        main_path,\n",
    "        f'pRFM/{subj}/ses-02/{denoising}/model-{atlas}-nelder-mead-GM_desc-prf_params_{filename_task}.pkl')\n",
    "    pkl_data = pickle_file(filepath)\n",
    "    prf_params = pkl_data['model'].iterative_search_params     \n",
    "    prf_voxels = np.where(pkl_data['rois_mask'] == 1)[0]\n",
    "    return prf_params, prf_voxels\n",
    "\n",
    "def filter_prf(prf_params, prf_voxels):\n",
    "    return PRFModel(\n",
    "        r2=prf_params[:, 7],\n",
    "        size=prf_params[:, 2],\n",
    "        ecc=np.sqrt(prf_params[:, 1]**2 + prf_params[:, 0]**2),\n",
    "        angle=np.arctan2(prf_params[:, 1], prf_params[:, 0]))\n",
    "\n",
    "def extract_prf(subj, hemi, target, csv_path, prf_params, prf_voxels):\n",
    "    best_fit = pd.read_csv(csv_path)\n",
    "\n",
    "    if 'Target Vertex Index' in best_fit.columns:\n",
    "        repeated_header_rows = best_fit['Target Vertex Index'] == 'Target Vertex Index'\n",
    "        if repeated_header_rows.any():\n",
    "            best_fit = best_fit[~repeated_header_rows]\n",
    "            # print(f\"Removed repeated header row in {csv_path}\")\n",
    "\n",
    "    best_fit['Source Vertex Index'] = best_fit['Source Vertex Index'].astype(int)\n",
    "    best_fit['Target Vertex Index'] = best_fit['Target Vertex Index'].astype(int)\n",
    "\n",
    "    prf_model = filter_prf(prf_params, prf_voxels)\n",
    "    lh_c = read_morph_data(f'{freesurfer}/{subj}/surf/lh.curv')\n",
    "    numel_lh = lh_c.shape[0]\n",
    "\n",
    "    if hemi == 'rh':\n",
    "        prf_voxels_rh = prf_voxels[prf_voxels >= numel_lh]\n",
    "        prf_voxels_rh_adjusted = prf_voxels_rh - numel_lh\n",
    "        prf_ecc_rh = prf_model.ecc[prf_voxels >= numel_lh]\n",
    "        prf_angle_rh = prf_model.angle[prf_voxels >= numel_lh]\n",
    "        voxel_to_ecc = dict(zip(prf_voxels_rh_adjusted, prf_ecc_rh))\n",
    "        voxel_to_angle = dict(zip(prf_voxels_rh_adjusted, prf_angle_rh))\n",
    "    else:\n",
    "        voxel_to_ecc = dict(zip(prf_voxels, prf_model.ecc))\n",
    "        voxel_to_angle = dict(zip(prf_voxels, prf_model.angle))\n",
    "\n",
    "    best_fit['Source Eccentricity'] = best_fit['Source Vertex Index'].map(voxel_to_ecc)\n",
    "    best_fit['Source Polar Angle'] = best_fit['Source Vertex Index'].map(voxel_to_angle)\n",
    "    return best_fit\n",
    "\n",
    "def header_fix(path, expected_column='Target Vertex Index'):\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for idx, line in enumerate(lines):\n",
    "        if expected_column in line:\n",
    "            header = line\n",
    "            data = lines[idx + 1:]\n",
    "            break\n",
    "    csv_content = ''.join([header] + data)\n",
    "    return pd.read_csv(io.StringIO(csv_content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj in subjects:\n",
    "    for task in tasks:\n",
    "        try:\n",
    "            prf_params, prf_voxels = load_prf(subj, MAIN_PATH, atlas, denoising, task)\n",
    "        except Exception as e:\n",
    "            print(f\"Missing pRF pkl file of Subject: {subj}, Task: {task}: {e}\")\n",
    "            continue\n",
    "\n",
    "        for hemi in hemispheres:\n",
    "            for target in visual_areas:\n",
    "                #best_fit_path = f'{MAIN_PATH}/CFM/{subj}/ses-1/GM/{hemi}/{denoising}/{task}/{target}/best_fits.csv'\n",
    "                #best_fit_path = f'{MAIN_PATH}/CFM/{subj}/ses-02/{atlas}/{task}/{denoising}/GM/{target}/{hemi}/{source}-{target}/best_fits.csv'\n",
    "                best_fit_path = f'{{MAIN_PATH}}/CFM/{subj}/ses-02/{atlas}/{task}/{denoising}/1/GM/lh/V1-V1/best_fits.csv'\n",
    "                if not os.path.exists(best_fit_path):\n",
    "                    print(f'Missing File of {subj}, {target}, {task}, {hemi}')\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    best_fit_prf = extract_prf(subj, hemi, target, best_fit_path, prf_params, prf_voxels)\n",
    "                except Exception as e:\n",
    "                    if isinstance(e, KeyError) and 'Source Vertex Index' in str(e):\n",
    "                        best_fit = header_fix(best_fit_path)\n",
    "                        best_fit.to_csv(best_fit_path, index=False) \n",
    "                        best_fit_prf = extract_prf(subj, hemi, target, best_fit_path, prf_params, prf_voxels)\n",
    "\n",
    "                output_path = f'{MAIN_PATH}/CFM/{subj}/ses-1/GM/{hemi}/{denoising}/{task}/{target}/best_fits_prf.csv'\n",
    "                best_fit_prf.to_csv(output_path, index=False)\n",
    "\n",
    "                target_idx = best_fit_prf['Target Vertex Index'].astype(int).values\n",
    "                curv = read_morph_data(f'{freesurfer}/{subj}/surf/{hemi}.curv')\n",
    "\n",
    "                def write_data_to_surface(values, suffix):\n",
    "                    masked = np.full(curv.shape[0], 50.0)\n",
    "                    masked[target_idx] = values\n",
    "                    output_file = f'{freesurfer}/{subj}/surf/{hemi}.{suffix}_{target}{source}_{denoising}_{task}'\n",
    "                    write_morph_data(output_file, masked)\n",
    "\n",
    "                write_data_to_surface(best_fit_prf['Source Eccentricity'].values, 'ecc')\n",
    "                write_data_to_surface(best_fit_prf['Source Polar Angle'].values, 'pol')\n",
    "                write_data_to_surface(best_fit_prf['Best Variance Explained Finer'].values, 've')\n",
    "                write_data_to_surface(best_fit_prf['Best Sigma Finer'].values, 'sigma')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pRFfitting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
