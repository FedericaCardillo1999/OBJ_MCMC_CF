{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Population Receptive Field properties for the Connective Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import pickle \n",
    "from nibabel.freesurfer.io import read_morph_data, write_morph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define whether you want to run the code on one subject or on the whole dataset\n",
    "\n",
    "# 1. Run the code on one specific subject \n",
    "# subjects = ['sub-02']\n",
    "\n",
    "# 2. Run the code on glaucoma patients \n",
    "subjects = [f'sub-{i:02}'for i in range(45,  47)]\n",
    "\n",
    "# 3. Run the code on healthy controls \n",
    "# subjects = [f'sub-{i:02}'for i in range(21, 47)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main variables \n",
    "target = 'V2'\n",
    "source = 'V1'\n",
    "hemi = 'rh' \n",
    "atlas = 'manual'\n",
    "delineation = 'manualdelin'\n",
    "denoising = 'nordic'\n",
    "task = 'RET'\n",
    "MAIN_PATH = '/Volumes/FedericaCardillo/pre-processing/projects/PROJECT_EGRET-AAA/derivatives'\n",
    "freesurfer = f\"{MAIN_PATH}/freesurfer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up all the functions needed to extract the pRF mapping properties \n",
    "class PRFModel:\n",
    "    def __init__(self, r2, size, ecc, angle):\n",
    "        self.r2 = r2        \n",
    "        self.size = size\n",
    "        self.ecc = ecc    \n",
    "        self.angle = angle     \n",
    "\n",
    "def pickle_file(filepath):\n",
    "    if not os.path.isfile(filepath):\n",
    "        raise FileNotFoundError(f\"File not found: {filepath}\")\n",
    "    with open(filepath, 'rb') as file: \n",
    "        return pickle.load(file)\n",
    "\n",
    "def load_prf(subj, main_path, atlas, denoising, task):\n",
    "    filepath = os.path.join(main_path, f'pRFM/{subj}/ses-02/{denoising}/model-{atlas}-nelder-mead-GM_desc-prf_params_{task}.pkl') \n",
    "    pkl_data = pickle_file(filepath)                       \n",
    "    prf_params = pkl_data['model'].iterative_search_params     \n",
    "    prf_voxels = np.where(pkl_data['rois_mask'] == 1)[0] \n",
    "    prf_voxels= prf_voxels\n",
    "    return prf_params, prf_voxels\n",
    "\n",
    "def filter_prf(prf_params, prf_voxels):\n",
    "    return PRFModel(\n",
    "        r2=prf_params[:, 7],                                              \n",
    "        size=prf_params[:, 2],                                              \n",
    "        ecc=np.sqrt(prf_params[:, 1]**2 + prf_params[:, 0]**2),      \n",
    "        angle=np.arctan2(prf_params[:, 1], prf_params[:, 0]))\n",
    "\n",
    "def extract_prf(subj, MAIN_PATH, atlas, denoising, task, csv_path):\n",
    "    best_fit = pd.read_csv(csv_path)\n",
    "    prf_params, prf_voxels = load_prf(subj, MAIN_PATH, atlas, denoising, task)\n",
    "    prf_model = filter_prf(prf_params, prf_voxels)\n",
    "    lh_c = read_morph_data(f'{freesurfer}/{subj}/surf/lh.curv')\n",
    "    numel_lh = lh_c.shape[0]\n",
    "\n",
    "    if hemi == 'rh':\n",
    "        prf_voxels_rh = prf_voxels[prf_voxels >= numel_lh] \n",
    "        prf_voxels_rh_adjusted = prf_voxels_rh - numel_lh \n",
    "        prf_ecc_rh = prf_model.ecc[prf_voxels >= numel_lh] \n",
    "        prf_angle_rh = prf_model.angle[prf_voxels >= numel_lh]\n",
    "        voxel_to_ecc = dict(zip(prf_voxels_rh_adjusted, prf_ecc_rh))\n",
    "        voxel_to_angle = dict(zip(prf_voxels_rh_adjusted, prf_angle_rh))\n",
    "    else: \n",
    "        voxel_to_ecc = dict(zip(prf_voxels, prf_model.ecc))\n",
    "        voxel_to_angle = dict(zip(prf_voxels, prf_model.angle))\n",
    "        \n",
    "    best_fit['Source Eccentricity'] = best_fit['Source Vertex Index'].map(voxel_to_ecc)\n",
    "    best_fit['Source Polar Angle'] = best_fit['Source Vertex Index'].map(voxel_to_angle)\n",
    "\n",
    "    output = f'/Volumes/FedericaCardillo/results/{subj}/{hemi}/{target}->{source}/best_fits_prf.csv'\n",
    "    best_fit.to_csv(output, index=False)\n",
    "    return best_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/FedericaCardillo/results/sub-45/rh/V2->V1/best_fits.csv\n",
      "Best fit file not found for sub-46.\n"
     ]
    }
   ],
   "source": [
    "for subj in subjects: \n",
    "    \n",
    "    best_fit_path = f'/Volumes/FedericaCardillo/results/{subj}/{hemi}/{target}->{source}/best_fits.csv' \n",
    "    if not os.path.exists(best_fit_path):\n",
    "        print(f'Best fit file not found for {subj}.')\n",
    "        continue\n",
    "\n",
    "    best_fit_prf = extract_prf(subj, MAIN_PATH, atlas, denoising, task, best_fit_path)\n",
    "    print(best_fit_path)\n",
    "    target_idx = best_fit_prf['Target Vertex Index'].values.astype(int)\n",
    "    \n",
    "    # ECCENTRICITY\n",
    "    target_ecc = best_fit_prf['Source Eccentricity'].values\n",
    "    curv = read_morph_data(f'{freesurfer}/{subj}/surf/{hemi}.curv')\n",
    "    masked_ecc = np.zeros(curv.shape[0])\n",
    "    masked_ecc[:] = 50 \n",
    "    masked_ecc[target_idx] = target_ecc\n",
    "    ecc_output = f'{freesurfer}/{subj}/surf/{hemi}.ecc_{target}{source}'\n",
    "    write_morph_data(ecc_output, masked_ecc)\n",
    "\n",
    "    # POLAR ANGLE \n",
    "    target_pol = best_fit_prf['Source Polar Angle'].values\n",
    "    masked_pol = np.zeros(curv.shape[0])\n",
    "    masked_pol[:] = 50 \n",
    "    masked_pol[target_idx] = target_pol\n",
    "    pol_output = f'{freesurfer}/{subj}/surf/{hemi}.pol_{target}{source}'\n",
    "    write_morph_data(pol_output, masked_pol)\n",
    "\n",
    "    # VARIANCE EXPLAINED \n",
    "    target_ve = best_fit_prf['Best Variance Explained Finer'].values\n",
    "    masked_ve = np.zeros(curv.shape[0])\n",
    "    masked_ve[:] = 50 \n",
    "    masked_ve[target_idx] = target_ve\n",
    "    ve_output = f'{freesurfer}/{subj}/surf/{hemi}.ve_{target}{source}'\n",
    "    write_morph_data(ve_output, masked_ve)\n",
    "\n",
    "    # SIGMA \n",
    "    target_sigma = best_fit_prf['Best Sigma Finer'].values\n",
    "    masked_sigma = np.zeros(curv.shape[0])\n",
    "    masked_sigma[:] = 50 \n",
    "    masked_sigma[target_idx] = target_sigma\n",
    "    sigma_output = f'{freesurfer}/{subj}/surf/{hemi}.sigma_{target}{source}'\n",
    "    write_morph_data(sigma_output, masked_sigma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pRFfitting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
