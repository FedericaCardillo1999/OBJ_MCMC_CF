{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Type of prf_params: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "subj = 'sub-46'\n",
    "subjectid = 'sub-46'\n",
    "subject = subjectid\n",
    "depth = 'GM'\n",
    "project = 'PROJECT_EGRET-AAA'\n",
    "space = 'fsnative'\n",
    "roi = ['all']\n",
    "r2_thr = 0.1\n",
    "target_visual_area = 2\n",
    "source_visual_area = 1\n",
    "hemi = 'rh'\n",
    "delineation = 'manualdelin'\n",
    "atlas = 'manual'\n",
    "denoising = 'nordic'\n",
    "task = 'RET'\n",
    "\n",
    "file_path = f'/Users/federicacardillo/Documents/GitHub/OBJ_MCMC_CF/OBJ_MCMC_CF/results/{subj}/{hemi}/V{target_visual_area}->V{source_visual_area}/best_fits.csv'  # Update with the actual path to your CSV file\n",
    "\n",
    "MAIN_PATH = '/Volumes/FedericaCardillo/pre-processing/projects/PROJECT_EGRET-AAA/derivatives'\n",
    "fs_dir = f\"{MAIN_PATH}/freesurfer\"\n",
    "labels_path = f\"{fs_dir}/{subj}/label/{hemi}.{delineation}.label\"\n",
    "\n",
    "# Define the pickle file path\n",
    "filepath = os.path.join(MAIN_PATH, f'pRFM/{subjectid}/ses-02/{denoising}/model-{atlas}-nelder-mead-GM_desc-prf_params_{task}.pkl')\n",
    "\n",
    "# Load the pickle file\n",
    "def load_pickle(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        return data\n",
    "pickle_data = load_pickle(filepath) # model, settings, pred_tc, rois_mask\n",
    "\n",
    "# Extract prf_params from the model\n",
    "if pickle_data and 'model' in pickle_data:\n",
    "    prf_params = pickle_data['model'].iterative_search_params\n",
    "    print(\"\\nType of prf_params:\", type(prf_params)) # (19073, 8)\n",
    "    r2 = prf_params[:, 7]  # Extract R2 values from column 7\n",
    "    size = prf_params[:, 2]  # Extract pRF size values from column 2\n",
    "    ecc = np.sqrt(prf_params[:, 1]**2 + prf_params[:, 0]**2)  # Calculate eccentricity\n",
    "    angle = np.arctan2(prf_params[:, 1], prf_params[:, 0])  # Calculate polar angle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248511\n",
      "(array([     0,      1,      2, ..., 248451, 248457, 248464]),)\n",
      "Shape of rois_mask: (248511,)\n",
      "(19073, 8)\n",
      "looking for ['/Volumes/FedericaCardillo/pre-processing/projects/PROJECT_EGRET-AAA/derivatives/freesurfer/sub-46/label/lh.benson14_eccen-0001.label', '/Volumes/FedericaCardillo/pre-processing/projects/PROJECT_EGRET-AAA/derivatives/freesurfer/sub-46/label/rh.benson14_eccen-0001.label']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0k/zjsxn2197mdbzvx14lj8m0v00000gn/T/ipykernel_71592/895534794.py:27: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  np.where(idx_vls4 == rois_list[1, np.where(rois_list[0] == roi)[0]])[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking for ['/Volumes/FedericaCardillo/pre-processing/projects/PROJECT_EGRET-AAA/derivatives/freesurfer/sub-46/label/lh.benson14_varea-0001.label', '/Volumes/FedericaCardillo/pre-processing/projects/PROJECT_EGRET-AAA/derivatives/freesurfer/sub-46/label/rh.benson14_varea-0001.label']\n",
      "looking for ['/Volumes/FedericaCardillo/pre-processing/projects/PROJECT_EGRET-AAA/derivatives/freesurfer/sub-46/label/lh.benson14_eccen-0001.label', '/Volumes/FedericaCardillo/pre-processing/projects/PROJECT_EGRET-AAA/derivatives/freesurfer/sub-46/label/rh.benson14_eccen-0001.label']\n",
      "looking for ['/Volumes/FedericaCardillo/pre-processing/projects/PROJECT_EGRET-AAA/derivatives/freesurfer/sub-46/label/lh.manualdelin.label', '/Volumes/FedericaCardillo/pre-processing/projects/PROJECT_EGRET-AAA/derivatives/freesurfer/sub-46/label/rh.manualdelin.label']\n"
     ]
    }
   ],
   "source": [
    "import cortex\n",
    "surfs = [cortex.polyutils.Surface(*d)\n",
    "         for d in cortex.db.get_surf(subject, \"fiducial\")]\n",
    "\n",
    "# First we need to import the surfaces for this subject\n",
    "numel_left = surfs[0].pts.shape[0]\n",
    "numel_right = surfs[1].pts.shape[0]\n",
    "numel = numel_left + numel_right\n",
    "print(numel)\n",
    "\n",
    "prf_params=[np.array([])]\n",
    "prf_params_vx=[np.array([])]\n",
    "rois_list = []\n",
    "rois_list = np.array([['V1','V2', 'V3'], [1, 2, 3]])\n",
    "rois = [['V1','V2', 'V3']]\n",
    "roi_verts=np.where(pickle_data['rois_mask']==1)\n",
    "print(roi_verts)\n",
    "print(\"Shape of rois_mask:\", pickle_data['rois_mask'].shape)\n",
    "prf_params=pickle_data['model'].iterative_search_params\n",
    "print(prf_params.shape)\n",
    "prf_params_vx=roi_verts[0]\n",
    "prf_params_vx = np.arange(prf_params.shape[0])  # Assign all vertex indices\n",
    "#print(prf_params_vx.shape)\n",
    "prf_params_vx = np.arange(numel)  # Include all vertices from FreeSurfer surface\n",
    "# Extract pRF model vertices for both hemispheres using idx_vls4\n",
    "roi_verts = np.concatenate([\n",
    "    np.where(idx_vls4 == rois_list[1, np.where(rois_list[0] == roi)[0]])[0]\n",
    "    for roi in rois_list[0]\n",
    "])\n",
    "prf_params_vx = roi_verts\n",
    "\n",
    "fs_dirPATH=f'{MAIN_PATH}/freesurfer'\n",
    "idx_rois1, idx_vls1 = cortex.freesurfer.get_label(subject, label='benson14_eccen-0001',fs_dir=fs_dirPATH,hemisphere=('lh', 'rh'),verbose=True)\n",
    "idx_rois4, idx_vls4 = cortex.freesurfer.get_label(subject, label='benson14_varea-0001',fs_dir=fs_dirPATH,hemisphere=('lh', 'rh'), verbose=True)\n",
    "\n",
    "if atlas=='manual':\n",
    "    idx_rois1, idx_vls1 = cortex.freesurfer.get_label(subject, label='benson14_eccen-0001',fs_dir=fs_dirPATH,hemisphere=('lh', 'rh'),verbose=True)\n",
    "    idx_rois5, idx_vls5 = cortex.freesurfer.get_label(subject, label='manualdelin',fs_dir=fs_dirPATH,hemisphere=('lh','rh'),verbose=True)\n",
    "    idx_vls4[idx_rois5]=idx_vls5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1\n",
      "V2\n",
      "V3\n",
      "Checking visual area: V1\n",
      "  Number of vertices in V1: 7868\n",
      "  ‚ùå Vertex 7370 is NOT present in V1.\n",
      "Checking visual area: V2\n",
      "  Number of vertices in V2: 7258\n",
      "  ‚ùå Vertex 7370 is NOT present in V2.\n",
      "Checking visual area: V3\n",
      "  Number of vertices in V3: 5170\n",
      "  ‚úÖ Vertex 7370 is present in V3!\n"
     ]
    }
   ],
   "source": [
    "rois_list = []\n",
    "rois_list = np.array([['V1','V2', 'V3'], [1, 2, 3]])\n",
    "rois = [['V1','V2', 'V3']]\n",
    "\n",
    "for r in range(rois[0].__len__()):\n",
    "    r2 = prf_params[:, 7]  # Extract R2 values from column 7\n",
    "    size = prf_params[:, 2]  # Extract pRF size values from column 2\n",
    "    ecc = np.sqrt(prf_params[:, 1]**2 + prf_params[:, 0]**2)  # Calculate eccentricity\n",
    "    angle = np.arctan2(prf_params[:, 1], prf_params[:, 0])  # Calculate polar angle\n",
    "    roi=rois[0][r]\n",
    "    print(roi)\n",
    "    roi_idx = np.where(rois_list[0] == roi)[0]\n",
    "    roi_verts = np.where(idx_vls4 == int(rois_list[1, roi_idx]))[0]\n",
    "\n",
    "    # Ensure right hemisphere vertices are included\n",
    "    idx = np.in1d(prf_params_vx, roi_verts) \n",
    "    \n",
    "vertex_to_check = 7370  # The vertex ID we want to verify\n",
    "\n",
    "for r in range(rois[0].__len__()):  \n",
    "    roi = rois[0][r]  \n",
    "    print(f\"Checking visual area: {roi}\")  \n",
    "    \n",
    "    # Get the corresponding visual area index\n",
    "    roi_idx = np.where(roi == rois_list[0, :])[0]\n",
    "    if len(roi_idx) == 0:\n",
    "        print(f\"  {roi} not found in rois_list\")\n",
    "        continue  # Skip if no match\n",
    "    \n",
    "    roi_verts = np.array(np.where(idx_vls4 == int(rois_list[1, roi_idx])))[0]  # Extract vertices in this region\n",
    "    \n",
    "    print(f\"  Number of vertices in {roi}: {len(roi_verts)}\")\n",
    "    \n",
    "    # Check if 6169 is in roi_verts\n",
    "    if vertex_to_check in roi_verts:\n",
    "        print(f\"  ‚úÖ Vertex {vertex_to_check} is present in {roi}!\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå Vertex {vertex_to_check} is NOT present in {roi}.\")\n",
    "\n",
    "    # You can also print the matching indices if needed\n",
    "    idx = np.in1d(prf_params_vx, roi_verts)  # Find matching indices\n",
    "    matching_vertices = prf_params_vx[idx]  # Filtered list of vertices in this ROI\n",
    "\n",
    "    if vertex_to_check in matching_vertices:\n",
    "        print(f\"  üîç Vertex {vertex_to_check} has pRF parameters assigned in {roi}!\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6747   7407   7370 ... 101014    255    256]\n",
      "(1657,)\n",
      "[116601   5467 123111 ... 102359    104    385]\n",
      "(1657,)\n"
     ]
    }
   ],
   "source": [
    "# Load CSV file and extract columns\n",
    "import pandas as pd\n",
    "df = pd.read_csv(file_path)\n",
    "target_vertex_index = df.iloc[:, 0].values \n",
    "print(target_vertex_index)\n",
    "print(target_vertex_index.shape)\n",
    "source_vertex_index = df.iloc[:, 1].values \n",
    "print(source_vertex_index)\n",
    "print(source_vertex_index.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total V1 vertices found: 7868\n",
      "Total V2 vertices found: 7258\n",
      "‚úÖ 412/1657 target vertices correctly assigned to V2.\n",
      "‚úÖ 410/1657 source vertices correctly assigned to V1.\n",
      "‚ùå 1245 target vertices (V2) are NOT in the pickle file as V2: [7407 7370 6732 6170 6169 7387 8012 7406 8044 8030]\n",
      "‚ùå 1247 source vertices (V1) are NOT in the pickle file as V1: [116601   5467 123111   7292   5571   5571 123111   7305   3633  10446]\n",
      "üîç 0/1657 target vertices have pRF parameters assigned.\n",
      "üîç 0/1657 source vertices have pRF parameters assigned.\n",
      "‚ö†Ô∏è 1657 target vertices do NOT have pRF parameters: [6747 7407 7370 6732 6170 6169 7387 8012 7406 8044]\n",
      "‚ö†Ô∏è 1657 source vertices do NOT have pRF parameters: [116601   5467 123111   7292   5571   5571 123111   7305   3633  10446]\n"
     ]
    }
   ],
   "source": [
    "# Extract visual area indices from idx_vls4\n",
    "v1_vertices = np.where(idx_vls4 == 1)[0]  # V1 vertices\n",
    "v2_vertices = np.where(idx_vls4 == 2)[0]  # V2 vertices\n",
    "\n",
    "print(f\"Total V1 vertices found: {len(v1_vertices)}\")\n",
    "print(f\"Total V2 vertices found: {len(v2_vertices)}\")\n",
    "\n",
    "# Check if all target_vertex_index are actually in V2\n",
    "v2_in_pickle = np.isin(target_vertex_index, v2_vertices)\n",
    "v1_in_pickle = np.isin(source_vertex_index, v1_vertices)\n",
    "\n",
    "# Count matches\n",
    "v2_correct_count = np.sum(v2_in_pickle)\n",
    "v1_correct_count = np.sum(v1_in_pickle)\n",
    "\n",
    "print(f\"‚úÖ {v2_correct_count}/{len(target_vertex_index)} target vertices correctly assigned to V2.\")\n",
    "print(f\"‚úÖ {v1_correct_count}/{len(source_vertex_index)} source vertices correctly assigned to V1.\")\n",
    "\n",
    "# Identify missing or incorrect assignments\n",
    "incorrect_v2 = target_vertex_index[~v2_in_pickle]\n",
    "incorrect_v1 = source_vertex_index[~v1_in_pickle]\n",
    "\n",
    "print(f\"‚ùå {len(incorrect_v2)} target vertices (V2) are NOT in the pickle file as V2: {incorrect_v2[:10]}\")\n",
    "print(f\"‚ùå {len(incorrect_v1)} source vertices (V1) are NOT in the pickle file as V1: {incorrect_v1[:10]}\")\n",
    "\n",
    "# Now, check if these vertices also exist in prf_params_vx (meaning they have pRF parameters assigned)\n",
    "v2_with_prf = np.isin(target_vertex_index, prf_params_vx)\n",
    "v1_with_prf = np.isin(source_vertex_index, prf_params_vx)\n",
    "\n",
    "print(f\"üîç {np.sum(v2_with_prf)}/{len(target_vertex_index)} target vertices have pRF parameters assigned.\")\n",
    "print(f\"üîç {np.sum(v1_with_prf)}/{len(source_vertex_index)} source vertices have pRF parameters assigned.\")\n",
    "\n",
    "# Identify missing pRF parameter assignments\n",
    "missing_v2_prf = target_vertex_index[~v2_with_prf]\n",
    "missing_v1_prf = source_vertex_index[~v1_with_prf]\n",
    "\n",
    "print(f\"‚ö†Ô∏è {len(missing_v2_prf)} target vertices do NOT have pRF parameters: {missing_v2_prf[:10]}\")\n",
    "print(f\"‚ö†Ô∏è {len(missing_v1_prf)} source vertices do NOT have pRF parameters: {missing_v1_prf[:10]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pRFfitting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
